{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from NeuralNetFuncs import preprocess_data, create_model\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n",
      "0  00008ff9                      Fall                5                0   \n",
      "1  000fd460                    Summer                9                0   \n",
      "2  00105258                    Summer               10                1   \n",
      "3  00115b9f                    Winter                9                0   \n",
      "4  0016bb22                    Spring               18                1   \n",
      "\n",
      "  CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  Physical-Height  \\\n",
      "0      Winter             51.0            Fall     16.877316             46.0   \n",
      "1         NaN              NaN            Fall     14.035590             48.0   \n",
      "2        Fall             71.0            Fall     16.648696             56.5   \n",
      "3        Fall             71.0          Summer     18.292347             56.0   \n",
      "4      Summer              NaN             NaN           NaN              NaN   \n",
      "\n",
      "   Physical-Weight  ...  PAQ_A-PAQ_A_Total  PAQ_C-Season  PAQ_C-PAQ_C_Total  \\\n",
      "0             50.8  ...                NaN           NaN                NaN   \n",
      "1             46.0  ...                NaN          Fall              2.340   \n",
      "2             75.6  ...                NaN        Summer              2.170   \n",
      "3             81.6  ...                NaN        Winter              2.451   \n",
      "4              NaN  ...               1.04           NaN                NaN   \n",
      "\n",
      "   PCIAT-Season SDS-Season  SDS-SDS_Total_Raw  SDS-SDS_Total_T  \\\n",
      "0          Fall        NaN                NaN              NaN   \n",
      "1          Fall       Fall               46.0             64.0   \n",
      "2          Fall       Fall               38.0             54.0   \n",
      "3        Summer     Summer               31.0             45.0   \n",
      "4           NaN        NaN                NaN              NaN   \n",
      "\n",
      "   PreInt_EduHx-Season PreInt_EduHx-computerinternet_hoursday  sii  \n",
      "0                 Fall                                    3.0  2.0  \n",
      "1               Summer                                    0.0  0.0  \n",
      "2               Summer                                    2.0  0.0  \n",
      "3               Winter                                    0.0  1.0  \n",
      "4                  NaN                                    NaN  NaN  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "pciat_columns = [col for col in df.columns if 'PCIAT-PCIAT' in col]\n",
    "df = df.drop(columns=pciat_columns)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
      "0    -3.685808  0.365580  1.513844 -0.557086 -2.735287  2.018432  1.888022   \n",
      "1    -1.510903 -0.676389  0.313244 -0.437976 -1.147098  1.281183 -0.032313   \n",
      "2    -5.090349 -2.007899  3.781410 -0.400749  2.408683 -2.786271 -1.271022   \n",
      "3    -1.066148 -0.479033 -0.163548 -1.445878  0.434594  0.127327 -0.839644   \n",
      "4    -0.209611 -0.101321 -0.123264 -0.694162  0.909159  1.573932  1.079984   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "5027  1.923964  2.524158  0.938433 -2.051517 -1.451526  1.591613 -0.959678   \n",
      "5028  7.605478  4.687524  1.857898  2.291448 -2.709162 -2.181858  0.890991   \n",
      "5029  5.487122  0.819260 -0.601589 -0.944500  0.022016  1.422174  0.039784   \n",
      "5030  2.376354  3.562526  2.265141 -5.166597 -2.972000  1.254447 -3.912509   \n",
      "5031  1.207396  2.809829  0.237983 -1.219144 -2.141105  5.814436  0.497510   \n",
      "\n",
      "           PC8       PC9      PC10  ...      PC22      PC23      PC24  \\\n",
      "0    -1.056939  1.284684  2.605241  ...  0.121335  1.208738 -1.408914   \n",
      "1    -0.024477  0.381139 -1.371333  ...  0.562340  0.352773 -1.043014   \n",
      "2     1.849048  0.078372  1.749909  ...  1.109867 -1.552396  0.420431   \n",
      "3     2.555420  0.365653  0.270348  ...  0.485481 -0.099387 -1.319163   \n",
      "4    -0.125843 -0.778089  2.195243  ...  0.620185  0.691140 -0.363645   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "5027 -1.141114 -0.958557 -1.491742  ... -0.352215 -0.225394  0.189706   \n",
      "5028  0.040073  0.541675 -1.879014  ... -0.584492 -0.108568 -0.150886   \n",
      "5029  3.214037 -0.143047 -0.486038  ...  1.283926 -0.255529  0.034163   \n",
      "5030 -1.123054 -2.692746 -1.105544  ... -1.383007  0.050316  0.630867   \n",
      "5031  1.036990  1.731309  2.252146  ... -1.169280 -0.020724  1.079629   \n",
      "\n",
      "          PC25      PC26      PC27      PC28      PC29      PC30      PC31  \n",
      "0     1.198863 -0.055124 -0.600505  1.060607  0.123075 -0.271448 -0.797152  \n",
      "1     0.905874 -0.303291 -1.192125  0.352100 -0.115900  0.822187 -0.512101  \n",
      "2     0.205927  0.293982 -0.471917 -0.158017 -0.289609  1.204090  0.397609  \n",
      "3     1.324752 -0.984713 -1.449443  0.267928 -0.314982 -1.160982  0.286614  \n",
      "4     0.126706  2.363235 -0.239878 -0.285781 -0.351489 -1.518038 -0.100446  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "5027  0.056782  0.021183 -0.040188  0.168939 -0.116178  0.132976 -0.606365  \n",
      "5028 -1.033741  0.468215 -0.143330 -0.694523 -0.160201 -0.166229  0.525755  \n",
      "5029  0.684565  0.504813  0.570816 -0.735508  0.196916 -0.555569 -0.641559  \n",
      "5030  0.403179  0.626785  0.576278  0.062278 -0.537369 -0.236950 -0.711291  \n",
      "5031 -0.153737  0.406947  0.997904 -0.170127  0.543086  0.298823  0.900765  \n",
      "\n",
      "[5032 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "X, y = preprocess_data(df)\n",
    "\n",
    "# First split the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE only to training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Scale the features using only training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Apply PCA using only training data\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled) \n",
    "# Convert to DataFrames\n",
    "X_train_df = pd.DataFrame(\n",
    "    X_train_pca,\n",
    "    columns=[f'PC{i+1}' for i in range(X_train_pca.shape[1])]\n",
    ")\n",
    "\n",
    "X_val_df = pd.DataFrame(\n",
    "    X_val_pca,\n",
    "    columns=[f'PC{i+1}' for i in range(X_val_pca.shape[1])]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Convert targets to categorical\n",
    "y_train_cat = to_categorical(y_train_resampled, num_classes=4)\n",
    "y_val_cat = to_categorical(y_val, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/Desktop/Autodesk/HealthPrediction/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.3397 - loss: 2.1621 - val_accuracy: 0.5547 - val_loss: 1.7693\n",
      "Epoch 2/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.5284 - loss: 1.6032 - val_accuracy: 0.5566 - val_loss: 1.4281\n",
      "Epoch 3/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6003 - loss: 1.3372 - val_accuracy: 0.5383 - val_loss: 1.3321\n",
      "Epoch 4/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.6205 - loss: 1.1787 - val_accuracy: 0.5347 - val_loss: 1.2848\n",
      "Epoch 5/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.6381 - loss: 1.0675 - val_accuracy: 0.5347 - val_loss: 1.1894\n",
      "Epoch 6/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.6513 - loss: 0.9939 - val_accuracy: 0.5639 - val_loss: 1.2409\n",
      "Epoch 7/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.6621 - loss: 0.9659 - val_accuracy: 0.5456 - val_loss: 1.1089\n",
      "Epoch 8/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.6674 - loss: 0.9136 - val_accuracy: 0.5547 - val_loss: 1.0943\n",
      "Epoch 9/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.6742 - loss: 0.8964 - val_accuracy: 0.5620 - val_loss: 1.0953\n",
      "Epoch 10/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.6764 - loss: 0.8700 - val_accuracy: 0.5566 - val_loss: 1.0879\n",
      "Epoch 11/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.6791 - loss: 0.8615 - val_accuracy: 0.5146 - val_loss: 1.1116\n",
      "Epoch 12/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.6739 - loss: 0.8457 - val_accuracy: 0.5547 - val_loss: 1.0860\n",
      "Epoch 13/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.6767 - loss: 0.8446 - val_accuracy: 0.5657 - val_loss: 1.0597\n",
      "Epoch 14/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.6860 - loss: 0.8308 - val_accuracy: 0.5055 - val_loss: 1.1136\n",
      "Epoch 15/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.6903 - loss: 0.8221 - val_accuracy: 0.5146 - val_loss: 1.1803\n",
      "Epoch 16/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.6850 - loss: 0.8084 - val_accuracy: 0.5383 - val_loss: 1.0976\n",
      "Epoch 17/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.6948 - loss: 0.8114 - val_accuracy: 0.5566 - val_loss: 1.0665\n",
      "Epoch 18/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.6883 - loss: 0.8078 - val_accuracy: 0.5657 - val_loss: 1.0929\n",
      "Epoch 19/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.6850 - loss: 0.7925 - val_accuracy: 0.5675 - val_loss: 1.0626\n",
      "Epoch 20/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7006 - loss: 0.7821 - val_accuracy: 0.5602 - val_loss: 1.0770\n",
      "Epoch 21/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - accuracy: 0.6864 - loss: 0.7982 - val_accuracy: 0.5474 - val_loss: 1.0963\n",
      "Epoch 22/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.7050 - loss: 0.7755 - val_accuracy: 0.5201 - val_loss: 1.1977\n",
      "Epoch 23/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7171 - loss: 0.7597 - val_accuracy: 0.5511 - val_loss: 1.0912\n",
      "Epoch 24/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7020 - loss: 0.7771 - val_accuracy: 0.5255 - val_loss: 1.1180\n",
      "Epoch 25/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.7014 - loss: 0.7695 - val_accuracy: 0.5474 - val_loss: 1.0685\n",
      "Epoch 26/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.7101 - loss: 0.7677 - val_accuracy: 0.5967 - val_loss: 1.0465\n",
      "Epoch 27/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.7017 - loss: 0.7742 - val_accuracy: 0.5438 - val_loss: 1.1529\n",
      "Epoch 28/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.7103 - loss: 0.7624 - val_accuracy: 0.5730 - val_loss: 1.0554\n",
      "Epoch 29/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7302 - loss: 0.7447 - val_accuracy: 0.5456 - val_loss: 1.0885\n",
      "Epoch 30/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.7117 - loss: 0.7471 - val_accuracy: 0.5547 - val_loss: 1.1058\n",
      "Epoch 31/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7167 - loss: 0.7528 - val_accuracy: 0.5438 - val_loss: 1.0984\n",
      "Epoch 32/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.7096 - loss: 0.7601 - val_accuracy: 0.5383 - val_loss: 1.0905\n",
      "Epoch 33/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7184 - loss: 0.7323 - val_accuracy: 0.5237 - val_loss: 1.2028\n",
      "Epoch 34/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.7232 - loss: 0.7378 - val_accuracy: 0.5839 - val_loss: 1.0533\n",
      "Epoch 35/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7319 - loss: 0.7315 - val_accuracy: 0.5620 - val_loss: 1.0858\n",
      "Epoch 36/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7318 - loss: 0.7248 - val_accuracy: 0.5474 - val_loss: 1.1984\n",
      "Epoch 37/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.7354 - loss: 0.7195 - val_accuracy: 0.5292 - val_loss: 1.1721\n",
      "Epoch 38/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7388 - loss: 0.7305 - val_accuracy: 0.5328 - val_loss: 1.1870\n",
      "Epoch 39/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7294 - loss: 0.7274 - val_accuracy: 0.5456 - val_loss: 1.1621\n",
      "Epoch 40/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7253 - loss: 0.7176 - val_accuracy: 0.5712 - val_loss: 1.0889\n",
      "Epoch 41/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.7350 - loss: 0.7205 - val_accuracy: 0.5602 - val_loss: 1.1457\n",
      "Epoch 42/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.7333 - loss: 0.7169 - val_accuracy: 0.5493 - val_loss: 1.1105\n",
      "Epoch 43/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.7401 - loss: 0.6999 - val_accuracy: 0.5566 - val_loss: 1.0996\n",
      "Epoch 44/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.7343 - loss: 0.7207 - val_accuracy: 0.5620 - val_loss: 1.1383\n",
      "Epoch 45/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.7287 - loss: 0.7182 - val_accuracy: 0.5365 - val_loss: 1.1682\n",
      "Epoch 46/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7469 - loss: 0.6931 - val_accuracy: 0.5566 - val_loss: 1.1421\n",
      "Epoch 47/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7381 - loss: 0.7167 - val_accuracy: 0.5438 - val_loss: 1.1503\n",
      "Epoch 48/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7501 - loss: 0.6874 - val_accuracy: 0.5602 - val_loss: 1.1558\n",
      "Epoch 49/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.7443 - loss: 0.6954 - val_accuracy: 0.5529 - val_loss: 1.1812\n",
      "Epoch 50/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7420 - loss: 0.7026 - val_accuracy: 0.5456 - val_loss: 1.1410\n",
      "Epoch 51/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7469 - loss: 0.6929 - val_accuracy: 0.5584 - val_loss: 1.1319\n",
      "Epoch 52/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7399 - loss: 0.6932 - val_accuracy: 0.5401 - val_loss: 1.1448\n",
      "Epoch 53/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.7471 - loss: 0.6885 - val_accuracy: 0.5493 - val_loss: 1.2091\n",
      "Epoch 54/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.7499 - loss: 0.6922 - val_accuracy: 0.5748 - val_loss: 1.2899\n",
      "Epoch 55/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7469 - loss: 0.6866 - val_accuracy: 0.5584 - val_loss: 1.2455\n",
      "Epoch 56/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7489 - loss: 0.6967 - val_accuracy: 0.5073 - val_loss: 1.2366\n",
      "Epoch 57/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.7401 - loss: 0.6911 - val_accuracy: 0.5566 - val_loss: 1.1645\n",
      "Epoch 58/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.7487 - loss: 0.6858 - val_accuracy: 0.5474 - val_loss: 1.3012\n",
      "Epoch 59/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.7631 - loss: 0.6773 - val_accuracy: 0.5785 - val_loss: 1.2479\n",
      "Epoch 60/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.7618 - loss: 0.6679 - val_accuracy: 0.5639 - val_loss: 1.2443\n",
      "Epoch 61/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7444 - loss: 0.6781 - val_accuracy: 0.5584 - val_loss: 1.2222\n",
      "Epoch 62/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.7474 - loss: 0.6792 - val_accuracy: 0.5712 - val_loss: 1.2117\n",
      "Epoch 63/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.7451 - loss: 0.6929 - val_accuracy: 0.5511 - val_loss: 1.2091\n",
      "Epoch 64/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.7627 - loss: 0.6579 - val_accuracy: 0.5712 - val_loss: 1.3262\n",
      "Epoch 65/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.7632 - loss: 0.6731 - val_accuracy: 0.5712 - val_loss: 1.2278\n",
      "Epoch 66/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.7537 - loss: 0.6770 - val_accuracy: 0.5894 - val_loss: 1.1427\n",
      "Epoch 67/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7579 - loss: 0.6682 - val_accuracy: 0.5474 - val_loss: 1.1800\n",
      "Epoch 68/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7538 - loss: 0.6716 - val_accuracy: 0.5438 - val_loss: 1.2067\n",
      "Epoch 69/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7649 - loss: 0.6618 - val_accuracy: 0.5766 - val_loss: 1.1700\n",
      "Epoch 70/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7656 - loss: 0.6653 - val_accuracy: 0.5748 - val_loss: 1.1537\n",
      "Epoch 71/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7699 - loss: 0.6600 - val_accuracy: 0.5620 - val_loss: 1.2169\n",
      "Epoch 72/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.7583 - loss: 0.6755 - val_accuracy: 0.5511 - val_loss: 1.2199\n",
      "Epoch 73/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7618 - loss: 0.6509 - val_accuracy: 0.5639 - val_loss: 1.2241\n",
      "Epoch 74/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7601 - loss: 0.6586 - val_accuracy: 0.5620 - val_loss: 1.1868\n",
      "Epoch 75/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.7682 - loss: 0.6491 - val_accuracy: 0.5401 - val_loss: 1.1980\n",
      "Epoch 76/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7621 - loss: 0.6541 - val_accuracy: 0.5693 - val_loss: 1.1976\n",
      "Epoch 77/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.7735 - loss: 0.6418 - val_accuracy: 0.5693 - val_loss: 1.1614\n",
      "Epoch 78/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7552 - loss: 0.6712 - val_accuracy: 0.5584 - val_loss: 1.2179\n",
      "Epoch 79/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7715 - loss: 0.6560 - val_accuracy: 0.5420 - val_loss: 1.2526\n",
      "Epoch 80/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7733 - loss: 0.6551 - val_accuracy: 0.5584 - val_loss: 1.2557\n",
      "Epoch 81/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.7708 - loss: 0.6565 - val_accuracy: 0.5675 - val_loss: 1.2091\n",
      "Epoch 82/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.7673 - loss: 0.6520 - val_accuracy: 0.5675 - val_loss: 1.2195\n",
      "Epoch 83/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7737 - loss: 0.6433 - val_accuracy: 0.5894 - val_loss: 1.2250\n",
      "Epoch 84/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.7723 - loss: 0.6417 - val_accuracy: 0.5693 - val_loss: 1.2369\n",
      "Epoch 85/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.7693 - loss: 0.6416 - val_accuracy: 0.5639 - val_loss: 1.2664\n",
      "Epoch 86/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.7725 - loss: 0.6428 - val_accuracy: 0.5730 - val_loss: 1.2343\n",
      "Epoch 87/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7742 - loss: 0.6371 - val_accuracy: 0.5675 - val_loss: 1.2079\n",
      "Epoch 88/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7654 - loss: 0.6574 - val_accuracy: 0.5401 - val_loss: 1.2604\n",
      "Epoch 89/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.7739 - loss: 0.6313 - val_accuracy: 0.5693 - val_loss: 1.2664\n",
      "Epoch 90/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.7794 - loss: 0.6375 - val_accuracy: 0.5675 - val_loss: 1.1761\n",
      "Epoch 91/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7817 - loss: 0.6426 - val_accuracy: 0.5584 - val_loss: 1.1969\n",
      "Epoch 92/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7661 - loss: 0.6619 - val_accuracy: 0.5584 - val_loss: 1.2090\n",
      "Epoch 93/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.7715 - loss: 0.6291 - val_accuracy: 0.5547 - val_loss: 1.3004\n",
      "Epoch 94/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7668 - loss: 0.6469 - val_accuracy: 0.5803 - val_loss: 1.3124\n",
      "Epoch 95/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - accuracy: 0.7778 - loss: 0.6300 - val_accuracy: 0.5712 - val_loss: 1.2648\n",
      "Epoch 96/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7822 - loss: 0.6133 - val_accuracy: 0.5547 - val_loss: 1.2459\n",
      "Epoch 97/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7801 - loss: 0.6282 - val_accuracy: 0.5693 - val_loss: 1.2260\n",
      "Epoch 98/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.7632 - loss: 0.6406 - val_accuracy: 0.5383 - val_loss: 1.2488\n",
      "Epoch 99/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.7947 - loss: 0.6158 - val_accuracy: 0.5493 - val_loss: 1.2325\n",
      "Epoch 100/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7763 - loss: 0.6327 - val_accuracy: 0.5328 - val_loss: 1.2348\n",
      "Epoch 101/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.7804 - loss: 0.6358 - val_accuracy: 0.5620 - val_loss: 1.2043\n",
      "Epoch 102/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7812 - loss: 0.6280 - val_accuracy: 0.5675 - val_loss: 1.1889\n",
      "Epoch 103/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7777 - loss: 0.6269 - val_accuracy: 0.5310 - val_loss: 1.3872\n",
      "Epoch 104/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.7781 - loss: 0.6247 - val_accuracy: 0.5365 - val_loss: 1.2830\n",
      "Epoch 105/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7842 - loss: 0.6228 - val_accuracy: 0.5365 - val_loss: 1.3450\n",
      "Epoch 106/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7813 - loss: 0.6114 - val_accuracy: 0.5566 - val_loss: 1.2970\n",
      "Epoch 107/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.7753 - loss: 0.6279 - val_accuracy: 0.5639 - val_loss: 1.2841\n",
      "Epoch 108/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.7846 - loss: 0.6250 - val_accuracy: 0.5529 - val_loss: 1.3250\n",
      "Epoch 109/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7914 - loss: 0.6175 - val_accuracy: 0.5675 - val_loss: 1.3151\n",
      "Epoch 110/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.7784 - loss: 0.6237 - val_accuracy: 0.5821 - val_loss: 1.2536\n",
      "Epoch 111/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.7825 - loss: 0.6237 - val_accuracy: 0.5730 - val_loss: 1.2313\n",
      "Epoch 112/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.7822 - loss: 0.6307 - val_accuracy: 0.5547 - val_loss: 1.2449\n",
      "Epoch 113/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7858 - loss: 0.6272 - val_accuracy: 0.5748 - val_loss: 1.2380\n",
      "Epoch 114/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.7867 - loss: 0.6205 - val_accuracy: 0.5712 - val_loss: 1.2598\n",
      "Epoch 115/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7755 - loss: 0.6343 - val_accuracy: 0.5803 - val_loss: 1.2066\n",
      "Epoch 116/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7784 - loss: 0.6156 - val_accuracy: 0.5712 - val_loss: 1.2500\n",
      "Epoch 117/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.7854 - loss: 0.6166 - val_accuracy: 0.5821 - val_loss: 1.2471\n",
      "Epoch 118/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7819 - loss: 0.6200 - val_accuracy: 0.5803 - val_loss: 1.2416\n",
      "Epoch 119/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7836 - loss: 0.6201 - val_accuracy: 0.5675 - val_loss: 1.2719\n",
      "Epoch 120/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.7865 - loss: 0.6264 - val_accuracy: 0.5693 - val_loss: 1.2407\n",
      "Epoch 121/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7863 - loss: 0.6065 - val_accuracy: 0.5639 - val_loss: 1.2171\n",
      "Epoch 122/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.7896 - loss: 0.6056 - val_accuracy: 0.5821 - val_loss: 1.3110\n",
      "Epoch 123/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.7828 - loss: 0.6245 - val_accuracy: 0.5511 - val_loss: 1.3163\n",
      "Epoch 124/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7833 - loss: 0.6218 - val_accuracy: 0.5584 - val_loss: 1.3780\n",
      "Epoch 125/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.7987 - loss: 0.6035 - val_accuracy: 0.5639 - val_loss: 1.3583\n",
      "Epoch 126/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7877 - loss: 0.6167 - val_accuracy: 0.5639 - val_loss: 1.2817\n",
      "Epoch 127/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.7851 - loss: 0.6147 - val_accuracy: 0.5620 - val_loss: 1.2760\n",
      "Epoch 128/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.8059 - loss: 0.5901 - val_accuracy: 0.5894 - val_loss: 1.2595\n",
      "Epoch 129/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.7926 - loss: 0.6040 - val_accuracy: 0.5766 - val_loss: 1.2706\n",
      "Epoch 130/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7979 - loss: 0.5943 - val_accuracy: 0.5712 - val_loss: 1.2918\n",
      "Epoch 131/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7957 - loss: 0.5953 - val_accuracy: 0.5657 - val_loss: 1.2875\n",
      "Epoch 132/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7789 - loss: 0.6249 - val_accuracy: 0.5511 - val_loss: 1.4107\n",
      "Epoch 133/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7940 - loss: 0.6013 - val_accuracy: 0.5712 - val_loss: 1.3695\n",
      "Epoch 134/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - accuracy: 0.7971 - loss: 0.5890 - val_accuracy: 0.5894 - val_loss: 1.3153\n",
      "Epoch 135/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7918 - loss: 0.5976 - val_accuracy: 0.5420 - val_loss: 1.4027\n",
      "Epoch 136/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7965 - loss: 0.6098 - val_accuracy: 0.5730 - val_loss: 1.3247\n",
      "Epoch 137/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.7922 - loss: 0.6062 - val_accuracy: 0.5365 - val_loss: 1.3977\n",
      "Epoch 138/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.8058 - loss: 0.5828 - val_accuracy: 0.5712 - val_loss: 1.3016\n",
      "Epoch 139/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.7748 - loss: 0.6214 - val_accuracy: 0.5602 - val_loss: 1.2887\n",
      "Epoch 140/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.7967 - loss: 0.6033 - val_accuracy: 0.5894 - val_loss: 1.2349\n",
      "Epoch 141/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.7988 - loss: 0.5996 - val_accuracy: 0.5785 - val_loss: 1.2231\n",
      "Epoch 142/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.7896 - loss: 0.6089 - val_accuracy: 0.5693 - val_loss: 1.3964\n",
      "Epoch 143/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7831 - loss: 0.6068 - val_accuracy: 0.5657 - val_loss: 1.2972\n",
      "Epoch 144/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.7968 - loss: 0.6006 - val_accuracy: 0.5584 - val_loss: 1.2979\n",
      "Epoch 145/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7887 - loss: 0.6093 - val_accuracy: 0.5657 - val_loss: 1.3438\n",
      "Epoch 146/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7850 - loss: 0.6135 - val_accuracy: 0.5803 - val_loss: 1.3417\n",
      "Epoch 147/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.7966 - loss: 0.6034 - val_accuracy: 0.5858 - val_loss: 1.2972\n",
      "Epoch 148/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.7902 - loss: 0.6104 - val_accuracy: 0.5803 - val_loss: 1.2854\n",
      "Epoch 149/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7925 - loss: 0.5946 - val_accuracy: 0.5602 - val_loss: 1.4178\n",
      "Epoch 150/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.7870 - loss: 0.6125 - val_accuracy: 0.5748 - val_loss: 1.3366\n",
      "Epoch 151/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.7964 - loss: 0.5995 - val_accuracy: 0.5931 - val_loss: 1.3393\n",
      "Epoch 152/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.7992 - loss: 0.5955 - val_accuracy: 0.5620 - val_loss: 1.3380\n",
      "Epoch 153/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7961 - loss: 0.5822 - val_accuracy: 0.5438 - val_loss: 1.3326\n",
      "Epoch 154/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7972 - loss: 0.5957 - val_accuracy: 0.5511 - val_loss: 1.3806\n",
      "Epoch 155/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.7857 - loss: 0.6098 - val_accuracy: 0.5949 - val_loss: 1.2180\n",
      "Epoch 156/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.7866 - loss: 0.5978 - val_accuracy: 0.5858 - val_loss: 1.2400\n",
      "Epoch 157/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7937 - loss: 0.6028 - val_accuracy: 0.5766 - val_loss: 1.3157\n",
      "Epoch 158/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.7848 - loss: 0.6025 - val_accuracy: 0.5730 - val_loss: 1.3520\n",
      "Epoch 159/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.7974 - loss: 0.5960 - val_accuracy: 0.5876 - val_loss: 1.3032\n",
      "Epoch 160/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.7933 - loss: 0.6063 - val_accuracy: 0.5748 - val_loss: 1.3295\n",
      "Epoch 161/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7989 - loss: 0.6051 - val_accuracy: 0.5730 - val_loss: 1.2355\n",
      "Epoch 162/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7905 - loss: 0.5878 - val_accuracy: 0.5748 - val_loss: 1.3624\n",
      "Epoch 163/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.7902 - loss: 0.6013 - val_accuracy: 0.5529 - val_loss: 1.2980\n",
      "Epoch 164/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7913 - loss: 0.5975 - val_accuracy: 0.6004 - val_loss: 1.3484\n",
      "Epoch 165/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.7859 - loss: 0.6013 - val_accuracy: 0.5657 - val_loss: 1.2605\n",
      "Epoch 166/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.7759 - loss: 0.6279 - val_accuracy: 0.5712 - val_loss: 1.2586\n",
      "Epoch 167/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.8033 - loss: 0.5861 - val_accuracy: 0.5620 - val_loss: 1.2858\n",
      "Epoch 168/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.7974 - loss: 0.5913 - val_accuracy: 0.5602 - val_loss: 1.3084\n",
      "Epoch 169/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.7959 - loss: 0.5894 - val_accuracy: 0.5712 - val_loss: 1.2687\n",
      "Epoch 170/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.8083 - loss: 0.5732 - val_accuracy: 0.5511 - val_loss: 1.3280\n",
      "Epoch 171/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.8034 - loss: 0.5833 - val_accuracy: 0.5584 - val_loss: 1.2847\n",
      "Epoch 172/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.8044 - loss: 0.5852 - val_accuracy: 0.5438 - val_loss: 1.3095\n",
      "Epoch 173/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.7917 - loss: 0.6021 - val_accuracy: 0.5657 - val_loss: 1.2518\n",
      "Epoch 174/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.7891 - loss: 0.6116 - val_accuracy: 0.5639 - val_loss: 1.3007\n",
      "Epoch 175/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.7956 - loss: 0.6122 - val_accuracy: 0.5639 - val_loss: 1.2990\n",
      "Epoch 176/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.8032 - loss: 0.5697 - val_accuracy: 0.5912 - val_loss: 1.4344\n",
      "Epoch 177/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.7894 - loss: 0.6049 - val_accuracy: 0.5584 - val_loss: 1.3250\n",
      "Epoch 178/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.8062 - loss: 0.5915 - val_accuracy: 0.5858 - val_loss: 1.3399\n",
      "Epoch 179/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.8033 - loss: 0.5800 - val_accuracy: 0.5931 - val_loss: 1.3516\n",
      "Epoch 180/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - accuracy: 0.7953 - loss: 0.5973 - val_accuracy: 0.5657 - val_loss: 1.3594\n",
      "Epoch 181/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.7945 - loss: 0.5974 - val_accuracy: 0.5821 - val_loss: 1.3609\n",
      "Epoch 182/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.7949 - loss: 0.5985 - val_accuracy: 0.5639 - val_loss: 1.3141\n",
      "Epoch 183/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.7989 - loss: 0.5844 - val_accuracy: 0.5511 - val_loss: 1.3517\n",
      "Epoch 184/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7987 - loss: 0.5858 - val_accuracy: 0.5730 - val_loss: 1.3068\n",
      "Epoch 185/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.8006 - loss: 0.5692 - val_accuracy: 0.5785 - val_loss: 1.3501\n",
      "Epoch 186/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7911 - loss: 0.5945 - val_accuracy: 0.5803 - val_loss: 1.3239\n",
      "Epoch 187/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.8069 - loss: 0.5748 - val_accuracy: 0.5730 - val_loss: 1.3344\n",
      "Epoch 188/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.7961 - loss: 0.5943 - val_accuracy: 0.5803 - val_loss: 1.3628\n",
      "Epoch 189/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.7995 - loss: 0.5781 - val_accuracy: 0.5602 - val_loss: 1.3223\n",
      "Epoch 190/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.7882 - loss: 0.5934 - val_accuracy: 0.5566 - val_loss: 1.3316\n",
      "Epoch 191/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329us/step - accuracy: 0.7972 - loss: 0.5777 - val_accuracy: 0.5511 - val_loss: 1.3326\n",
      "Epoch 192/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.7898 - loss: 0.6031 - val_accuracy: 0.5894 - val_loss: 1.2906\n",
      "Epoch 193/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.7979 - loss: 0.5870 - val_accuracy: 0.5529 - val_loss: 1.3441\n",
      "Epoch 194/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.8131 - loss: 0.5653 - val_accuracy: 0.5876 - val_loss: 1.2731\n",
      "Epoch 195/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.8124 - loss: 0.5646 - val_accuracy: 0.5839 - val_loss: 1.2825\n",
      "Epoch 196/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.8120 - loss: 0.5797 - val_accuracy: 0.5785 - val_loss: 1.3225\n",
      "Epoch 197/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.8013 - loss: 0.5785 - val_accuracy: 0.5985 - val_loss: 1.3589\n",
      "Epoch 198/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.8013 - loss: 0.5824 - val_accuracy: 0.5493 - val_loss: 1.3257\n",
      "Epoch 199/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.8152 - loss: 0.5665 - val_accuracy: 0.5931 - val_loss: 1.3115\n",
      "Epoch 200/200\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.8028 - loss: 0.5814 - val_accuracy: 0.5730 - val_loss: 1.3135\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model = create_model(X_train_df.shape[1])\n",
    "history = model.fit(\n",
    "    X_train_df, \n",
    "    y_train_cat,\n",
    "    validation_data=(X_val_df, y_val_cat),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250us/step\n",
      "\n",
      "Training Accuracy: 0.8595\n",
      "Validation Accuracy: 0.5730\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "y_train_pred = np.argmax(model.predict(X_train_df), axis=1)\n",
    "y_val_pred = np.argmax(model.predict(X_val_df), axis=1)\n",
    "y_train_true = np.argmax(y_train_cat, axis=1)\n",
    "y_val_true = np.argmax(y_val_cat, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = (y_train_pred == y_train_true).mean()\n",
    "val_accuracy = (y_val_pred == y_val_true).mean()\n",
    "\n",
    "print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.73       336\n",
      "           1       0.33      0.41      0.37       131\n",
      "           2       0.33      0.32      0.33        72\n",
      "           3       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.57       548\n",
      "   macro avg       0.35      0.36      0.36       548\n",
      "weighted avg       0.59      0.57      0.58       548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val_true, y_val_pred)\n",
    "\n",
    "# Plot confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1, 2, 3], yticklabels=[0, 1, 2, 3])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val_true, y_val_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
